<!DOCTYPE html> <html lang="en"> <head> <meta name="google-site-verification" content=""/><meta name="msvalidate.01" content=""/> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"/> <meta name="google-site-verification" content="G0dKOdodnI1to8KDwIDw0hhLXmwuBd1_RyVru3rq1sc"/> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Chen Chu</title> <meta name="author" content="Chen Chu"/> <meta name="description" content="Chen Chu USC "/> <meta name="keywords" content="Giser, Spatial Data Scientist"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/USC.png"/> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://chuchen2017.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blogs</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Chen Chu </h1> <p class="desc"><b>Spatial Data Scientist.</b></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/chuchen-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/chuchen-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/chuchen-1400.webp"/> <img src="/assets/img/chuchen.jpg?e62207f94d0d6c517697b0ed247cc94e" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="chuchen.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="address"> <p>Los Angeles</p> </div> </div> <div class="clearfix"> <p>Hi! I am <code class="language-plaintext highlighter-rouge">Chen Chu</code> (初晨), I am a first-year Computer Science Ph.D. student at the University of Southern California(USC), advised by Professor <a href="https://infolab.usc.edu/">Cyrus Shahabi</a>. I am passionate about developing SOTA AI models to solve spatial problems, which involved trajectory modeling and prediction, spatial representation learning.</p> <p>Standing at the frontier that bridges spatial data science and Artificial Intelligence, I believe the next turning point of spatial AI will be brought by a unified representation learning method of space and spatial entities.</p> <p>Prior to my Ph.D., I earned my Master degree from State Key Laboratory of Resources and Environmental Information System(LREIS), University of Chinese Academy of Sciences(UCAS), where I was supervised by Professor <a href="https://scholar.google.com/citations?user=oeS87xoAAAAJ&amp;hl=zh-CN">Feng Lu</a> and Associate Professor <a href="https://scholar.google.com/citations?user=ys6nhTMAAAAJ&amp;hl=zh-CN&amp;oi=ao">Hengcai Zhang</a>.</p> <p>My research interests include <strong>Human Mobility Modeling</strong>, <strong>Spatially Representation Learning</strong>, <strong>Generative AI</strong>.</p> <p>Please feel free to reach out! chenchu@usc.edu</p> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/diffusion.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/diffusion.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/diffusion.gif-1400.webp"/> <img src="/assets/img/publication_preview/diffusion.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="diffusion.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div id="IJGIS" class="col-sm-8"> <div class="title">Simulating Human Mobility with a Trajectory Generation Framework Based on Diffusion Model</div> <div class="author"> <em>Chen Chu</em>,&nbsp;Zhang Hengcai,&nbsp;and&nbsp;Lu Feng</div> <div class="periodical"> <em><b>International Journal of Geographical Information Science</b></em>, Aug 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/diffusion.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Most of the current mobility modeling methods are specially designed to solve one specific task, which leads to questions regarding generalizability. Inspired by the bloom of foundation models, we proposed a generalized Trajectory Generation framework based on Diffusion Model (TrajGDM) to capture the universal mobility pattern in a trajectory dataset by learning the trajectory-generation process. The process is modeled as a step-by-step uncertainty reducing process, which estimates uncertainty with a trajectory generator network. We compared the proposed trajectory generation method with five benchmarks on two public trajectory datasets. The result showed that the similarity between generated and real trajectory movements measured by Jensen-Shannon Divergence improved by at least 50.3% on both datasets. Moreover, we applied zero-shot inferences to two basic trajectory tasks: trajectory prediction and trajectory reconstruction. The zero-shot prediction accuracy of our model is up to 23.4% higher than the benchmark, and the reconstruction accuracy improves by a maximum of 25.6%. The universal mobility pattern that suits for solving multiple trajectory tasks is verified by the zero-shot multi-tasks inferring ability of our model. At last, the study gave insights into the generation of trajectories by exploring the way the model maps trajectory’s representation in the latent space into reality.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/website_poster_compressed-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/website_poster_compressed-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/website_poster_compressed-1400.webp"/> <img src="/assets/img/publication_preview/website_poster_compressed.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="website_poster_compressed.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div id="SIGSPATIAL" class="col-sm-8"> <div class="title">TrajGDM: A New Trajectory Foundation Model for Simulating Human Mobility</div> <div class="author"> <em>Chen Chu</em>,&nbsp;Zhang Hengcai,&nbsp;and&nbsp;Lu Feng</div> <div class="periodical"> <em><b>ACM SIGSPATIAL 2023 SRC</b></em>, Nov 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/ACM_SIGSPATIAL.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Capturing the universal movement pattern and simulating human mobility is one of the most important trajectory data-mining tasks. Most of the current mobility modeling methods are specially designed to solve a specific task, which leads to questions regarding generalizability. Aiming to construct a general trajectory foundation model to overcome this weakness, we proposed a generative Trajectory Generation framework based on Diffusion Model (TrajGDM) to capture the universal mobility pattern and simulate human mobility. It is capable of solving multiple trajectory tasks through learning the generation of the trajectory. The generation process of a trajectory is modeled as a step-by-step uncertainty reducing process. A trajectory generator network is proposed to estimate the uncertainty in each step, and a trajectory diffusion and generation process is defined to train the model to simulate the real dataset. Finally, we compared the proposed method with 5 strong baselines on 2 public trajectory datasets: T-Drive and Geo-life. By comparing 5 different evaluation metrics, the result showed that the similarity between generated and real trajectories’ movements measured by Jensen-Shannon Divergence improved by at least 50.3% in both datasets. It also addresses the problem of generating diverse trajectories, which is ignored by most previous models. Then, we conducted zero-shot experiments on two trajectory tasks, trajectory prediction and reconstruction. In trajectory prediction, the accuracy of TrajGDM’s zero-shot inference is up to 23.4% higher than that of the benchmark method, and the reconstruction accuracy increased by a maximum of 25.6%.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/DeepIndoorCrowd-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/DeepIndoorCrowd-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/DeepIndoorCrowd-1400.webp"/> <img src="/assets/img/publication_preview/DeepIndoorCrowd.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="DeepIndoorCrowd.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div id="TGIS" class="col-sm-8"> <div class="title">DeepIndoorCrowd: Predicting Crowd Flow in Indoor Shopping Malls with an Interpretable Transformer Network</div> <div class="author"> <em>Chen Chu</em>,&nbsp;Zhang Hengcai,&nbsp;Wang Peixiao, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Lu Feng' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span></div> <div class="periodical"> <em><b>Transactions in GIS</b></em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/DeepIndoorCrowd.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="http://doi.org/10.1111/tgis.13095"></span> <span class="__dimensions_badge_embed__" data-doi="http://doi.org/10.1111/tgis.13095" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Accurate and interpretable prediction of crowd flow would benefit business management and public security. The existing studies are challenged to adapt to the indoor environment due to its complex and dynamic spatial interaction patterns. In this study, we propose a crowd flow predicting method for indoor shopping malls, which simultaneously features temporal variables and semantic factors to suit the shopping mall environment. A deep learning model named DeepIndoorCrowd is presented. The model aims at capturing temporal dependencies and the semantic pattern in crowd flow to generate an accurate multi-horizon prediction. With a multi-term temporal dependencies capturing structure, the model is effective in learning both daily and weekly patterns of the indoor crowd flow in a shopping mall and is able to provide the temporal interpretation of the prediction result. Moreover, a semantic-temporal fusion module is introduced to utilize the semantic information of stores in prediction, which was proved to be effective in enhancing the model’s ability to learn temporal patterns. Experiments were conducted on a real-world dataset to verify the proposed predicting approach. The ablation study demonstrates that the DeepIndoorCrowd can effectively improve the efficiency and accuracy of the prediction, and the accuracy increment is up to 18.7%. In addition, some interesting indoor crowd flow patterns were discovered by analyzing model’s interpretation to the prediction result. The proposed prediction method provides an intuitive way of modeling indoor crowd flow, and the experiment’s outcome can help indoor managers better understand stores’ flow traffic.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/Manuscript_JATM-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/Manuscript_JATM-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/Manuscript_JATM-1400.webp"/> <img src="/assets/img/publication_preview/Manuscript_JATM.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="Manuscript_JATM.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div id="JATM" class="col-sm-8"> <div class="title">Assessing Impacts of the Russia-Ukraine Conflict on Global Air Transportation: from the View of Mass Flight Trajectories</div> <div class="author"> <em>Chen Chu</em>,&nbsp;Zhang Hengcai,&nbsp;Zhang Jiayin, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Lu Feng' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span></div> <div class="periodical"> <em><b>Journal of Air Transport Management</b></em>, Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/JATM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="https://doi.org/10.1016/j.jairtraman.2023.102522"></span> <span class="__dimensions_badge_embed__" data-doi="https://doi.org/10.1016/j.jairtraman.2023.102522" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Air transportation has been severely affected by the Russia-Ukraine conflict. The closure of involved Russian and Ukrainian airspace made a great number of flights suffer from a dramatic transportation cost increase. Accurately estimating the conflict’s impact can help us better comprehend the susceptibility of international airlines and optimize flying routes for global airlines. In this study, we quantitatively analyzed the impact the conflict has brought on global air transportation. The detour of airlines and the variation of flights caused by the conflict were assessed from the view of mass flight trajectories. A flight cost increment index is proposed to reveal the extra costs of involved countries. The impacts on each involved country are further analyzed and the airlines influenced the most are identified. The results show that the flight cost of 6.23% of global international flights significantly increased by 13.32% due to the conflict. Furthermore, as one of the few researches that analyze the impact of regional events on global air transportation, the result of the study reveals the vulnerability of international airlines and provides instruction for flying route optimization.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/JGIS-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/JGIS-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/JGIS-1400.webp"/> <img src="/assets/img/publication_preview/JGIS.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="JGIS.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div id="JGIS" class="col-sm-8"> <div class="title">Inferring Consumption Behavior of Customers in Shopping Malls from Indoor Trajectories</div> <div class="author"> <em>Chen Chu</em>,&nbsp;Zhang Hengcai,&nbsp;and&nbsp;Lu Feng</div> <div class="periodical"> <em><b>Journal of Geo-Information Science</b></em>, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/JGIS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.12082/dqxxkx.2022.210690"></span> <span class="__dimensions_badge_embed__" data-doi="10.12082/dqxxkx.2022.210690" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>How to obtain the consumption behavior of massive customers in large indoor shopping malls has always been a difficult problem in behavioral geography. However, with the explosive growth of indoor trajectory data in recent years, there’s a great opportunity to solve this problem. Meanwhile, the lack of semantic information and poor data quality of indoor trajectory still pose challenges to the inference of consumer behavior. This study proposes a framework for customers’ consumption behavior inference in shopping malls without collecting private personal consumption records. This framework integrates the Web text information of stores with movement features extracted from personal and historical customer trajectories. The semantic attributes of indoor stores are enhanced by introducing the crawled network text data of indoor stores, so as to realize the transformation from customer geometric trajectory to semantic trajectory. Specifically, the framework offers a method to model the customers’ consumption feature from three aspects, including the raw trajectory’s movement feature, semantic feature, and movement embedding feature. By employing the representation learning algorithm in extraction of customers’ movement embedding feature, the framework can learn the movement pattern from the historical crowd trajectories and use the movement embedding feature to model movements of a single customer in a complex indoor environment automatically. Finally, the research realizes residents’ consuming behavior inference by clustering the concatenated multi-sources consuming features and analyzing the clusters with statistic values and visualization. Through the experimental analysis of a real-world indoor trajectory dataset generated from a large shopping mall with 7045 customers, the inference result proves that the framework can effectively extract the spatial-temporal movement and consumption pattern of residents. Comparing with the classic feature extraction methods and typical clustering methods, the framework we propose achieves an improvement for up to 69.8% in the Silhouette Coefficient. This improvement illustrates that the customers’ consumption behavior inferring framework we propose can identify the customers with different consuming behaviors more effectively and cluster customers’ feature with high dimension more precisely. Through the analysis of indoor customer clusters’ movement pattern, the research finds out that the moving behavior of all shopping mall customers are affected directly and prominently by the design of indoor environment e.g., the distribution of functional zones, location of escalators, etc. Besides, the research also finds out that customers have strong preference to consume in the identical floor. The framework we proposed can identify customer groups with different consumption levels and movement patterns and discover consuming patterns from massive shopping mall customers without knowing their personal information. The application of the framework in inferring customer behavior patterns could provide a support for relative researches in behavioral geography.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/AppliedScience2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/AppliedScience2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/AppliedScience2-1400.webp"/> <img src="/assets/img/publication_preview/AppliedScience2.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="AppliedScience2.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div id="app12094412" class="col-sm-8"> <div class="title">Outlier Reconstruction of NDVI for Vegetation-Cover Dynamic Analyses</div> <div class="author"> Zhengbao Sun,&nbsp;Lizhen Wang,&nbsp;<em>Chen Chu</em>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Yu Zhang' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span></div> <div class="periodical"> <em><b>Applied Sciences</b></em>, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/AppliedScience.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.3390/app12094412"></span> <span class="__dimensions_badge_embed__" data-doi="10.3390/app12094412" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>The normalized difference vegetation index (NDVI) contains important data for providing vegetation-cover information and supporting environmental analyses. However, understanding long-term vegetation cover dynamics remains challenging due to data outliers that are found in cloudy regions. In this article, we propose a sliding-window-based tensor stream analysis algorithm (SWTSA) for reconstructing outliers in NDVI from multitemporal optical remote-sensing images. First, we constructed a tensor stream of NDVI that was calculated from clear-sky optical remote-sensing images corresponding to seasons on the basis of the acquired date. Second, we conducted tensor decomposition and reconstruction by SWTSA. Landsat series remote-sensing images were used in experiments to demonstrate the applicability of the SWTSA. Experiments were carried out successfully on the basis of data from the estuary area of Salween River in Southeast Asia. Compared with random forest regression (RFR), SWTSA has higher accuracy and better reconstruction capabilities. Results show that SWTSA is reliable and suitable for reconstructing outliers of NDVI from multitemporal optical remote-sensing images.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/light2021-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/light2021-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/light2021-1400.webp"/> <img src="/assets/img/publication_preview/light2021.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="light2021.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div id="IEEE JSTARS" class="col-sm-8"> <div class="title">Assessing Light Pollution Using POI and Luojia1-01 Night-Time Imagery From a Quantitative Perspective at City Scale</div> <div class="author"> Fei Zhao(Supervisor),&nbsp;<em>Chen Chu</em>,&nbsp;Rui Liu, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Zhiyan Peng, Qingyun Du, Zhiqiang Xie, Zhengbao Sun, Hongyun Zeng, Jisheng Xia' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span></div> <div class="periodical"> <em><b>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</b></em>, Dec 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/light2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1109/JSTARS.2021.3097320"></span> <span class="__dimensions_badge_embed__" data-doi="10.1109/JSTARS.2021.3097320" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In previous studies using night-time light (NTL) image in analyzing light pollution, most of the researchers focused on national or regional scale analysis. While in this article we focus on the perception of light pollution’s influence to the environment of human settlement. We propose an analysis method mainly utilizing NTL images and a city’s point of interest (POI) data to assess the light pollution from the aspect of its impact on the environment of city residents. The method quickly provides light pollution analysis at a fine spatial scale. We also address the POI data in a novel aggregating algorithm to better construct the area of interest, which can conquer the limitation of spatial resolution of NTL data in some extent. By doing the assessment in two Chinese medium-size cities, light pollution sources, the pollution level for each residence are found and analyzed. Furthermore, several light pollution patterns are discovered and interpreted. The result of the experiment demonstrates our assessment method provides a fast way to analyze light pollution patterns and can show the detailed light pollution situation in a city.</p> </div> </div> </div> </li></ol> </div> <h2><a style="color: inherit;">Awards</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jun 30, 2024</th> <td> 2024 Outstanding Graduates of IGSNRR, CAS (top 5%) </td> </tr> <tr> <th scope="row">Nov 16, 2023</th> <td> 2023 Second place at ACM SIGSPATIAL Student Research Competition graduate track </td> </tr> <tr> <th scope="row">Nov 12, 2023</th> <td> 2023 ACM SIGSPATIAL Student Travel Grant </td> </tr> <tr> <th scope="row">Oct 23, 2023</th> <td> 2023 First Class Director’s Scholarship of IGSNRR, CAS (top 15%) </td> </tr> <tr> <th scope="row">Oct 20, 2023</th> <td> 2023 First Class Academic Scholarship of IGSNRR, CAS </td> </tr> <tr> <th scope="row">Jun 1, 2023</th> <td> 2023 Merit Student of University of Chinese Academy of Science </td> </tr> <tr> <th scope="row">Dec 31, 2022</th> <td> 2022 Merit Student of University of Chinese Academy of Science </td> </tr> <tr> <th scope="row">Dec 1, 2022</th> <td> 2022 Academic Scholarship of IGSNRR, CAS </td> </tr> <tr> <th scope="row">Jan 1, 2022</th> <td> 2022 Outstanding Student Award of University of Chinese Academy of Science </td> </tr> <tr> <th scope="row">Jul 1, 2021</th> <td> 2021 Principal’s Scholarship of Yunnan University (10 out of all 4000+ undergraduate students) </td> </tr> <tr> <th scope="row">Jun 1, 2021</th> <td> 2021 Outstanding Bachelor’s Thesis Award of Yunnan University . </td> </tr> <tr> <th scope="row">Dec 31, 2020</th> <td> 2020 Chinese National Scholarship (top 0.5%) </td> </tr> <tr> <th scope="row">Jun 1, 2020</th> <td> 2020 Excellent Student Cadre of Yunnan Province </td> </tr> </table> </div> </div> <h2><a href="/blog/" style="color: inherit;">Blogs</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Nov 16, 2023</th> <td> <a class="news-title" href="/blog/2023/GIS/">We won the second place at SIGSPATIAL 2023 Student Research Competition</a> </td> </tr> <tr> <th scope="row">May 21, 2023</th> <td> <a class="news-title" href="/blog/2023/GISChina/">Speech at GIS China 2023</a> </td> </tr> <tr> <th scope="row">Mar 1, 2023</th> <td> <a class="news-title" href="/blog/2023/basketball/">My basketball career</a> </td> </tr> <tr> <th scope="row">Jul 20, 2019</th> <td> <a class="news-title" href="/blog/2019/YNU/">My parents are invited to deliver a speech at the graduation ceremony of YNU.</a> </td> </tr> <tr> <th scope="row">Jul 20, 2019</th> <td> <a class="news-title" href="/blog/2019/UK/">Studying at Lancaster University</a> </td> </tr> </table> </div> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%63%68%65%6E%63%68%75@%75%73%63.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> </div> <div class="contact-note"> Please feel free to reach out! E-mail: chenchu@usc.edu </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> &copy; Copyright 2025 Chen Chu. Feel free to contact. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>